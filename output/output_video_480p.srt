1
00:00:00,000 --> 00:00:03,420
好的 各位同學們 我們現在看到這張投影片

2
00:00:03,420 --> 00:00:06,160
主題是混小舉證 Confusion Matrix

3
00:00:06,160 --> 00:00:10,040
這葉投影片主要想帶大家認識在處理不平衡資料時

4
00:00:10,040 --> 00:00:11,580
混小舉證的重要性

5
00:00:11,580 --> 00:00:14,580
舉例來說 我們看到這裏有兩組資料

6
00:00:14,580 --> 00:00:17,240
其中一組是10比資料中只有1個1

7
00:00:17,240 --> 00:00:20,040
另一組是也是10比資料中只有1個0

8
00:00:20,040 --> 00:00:21,640
這就是一種不平衡的狀況

9
00:00:21,640 --> 00:00:24,720
接着 投影片列出了三個不同的Score

10
00:00:24,720 --> 00:00:29,020
這個Score簡單來說 就是在預測結果中我們預測證確的比例

11
00:00:29,100 --> 00:00:33,900
大家可以看到 即使Score很高 像是0.7 0.8 甚至0.9

12
00:00:33,900 --> 00:00:35,180
但因爲資料不平衡

13
00:00:35,180 --> 00:00:37,140
高Score不代表模型真的有效

14
00:00:37,140 --> 00:00:39,340
我們需要使用混小舉證來進一步分析

15
00:00:39,340 --> 00:00:42,340
才能知道模型在少數類別上的預測能力

16
00:00:42,580 --> 00:00:46,180
好的 針對這張投影片 我來經淺一下講稿

17
00:00:46,180 --> 00:00:47,180
講稿

18
00:00:47,180 --> 00:00:50,940
好 這張投影片我們要來看什麼是混小舉證

19
00:00:50,940 --> 00:00:53,060
也就是 Confusion Matrix

20
00:00:53,060 --> 00:00:55,780
混小舉證會幫我們評估模型的預測結果

21
00:00:55,780 --> 00:00:59,580
像是判斷是不是Nought的11 把預測跟實際的狀況做比較

22
00:00:59,580 --> 00:01:01,300
這個舉證分成四的部分

23
00:01:01,300 --> 00:01:06,260
如果實際是Nought的11 模型也預測是Nought的11 就是 True Negative

24
00:01:06,260 --> 00:01:11,180
如果實際不是Nought的11 模型確判斷它是就是 False Positive

25
00:01:11,180 --> 00:01:16,660
反過來 如果實際不是Nought的11 模型預測是Nought的11 就是 False Negative

26
00:01:16,660 --> 00:01:22,100
最後 如果實際不是Nought的11 模型也預測不是Nought的11 就是 True Positive

27
00:01:22,180 --> 00:01:27,780
最後我們看到 投影片上著名了這是國力中心大學統計所臨場雲教授的資料

28
00:01:27,780 --> 00:01:30,260
好的 針對這張投影片

29
00:01:30,260 --> 00:01:31,460
我們可以這樣講

30
00:01:31,460 --> 00:01:34,460
這張投影片介紹了幾個評估模型的重要指標

31
00:01:34,460 --> 00:01:38,700
Precision 精確度 Recall 照回率和 FESCORE

32
00:01:38,700 --> 00:01:43,660
Precision 衡量的是所有被預測爲證力的樣本中真正是證力的比例

33
00:01:43,660 --> 00:01:45,900
公式在這裏 大家可以看到

34
00:01:46,020 --> 00:01:48,900
Recall 則衡量的是所有實際證力的樣本中

35
00:01:48,900 --> 00:01:53,540
被證確於測爲證力的比例也就是 True Positive Rate或 Sensitivity

36
00:01:53,540 --> 00:01:59,420
最後 FESCORE 是 Precision和 Recall的調和平均數可以綜合衡量模型的表現

37
00:01:59,420 --> 00:02:00,900
公式也列在上面

38
00:02:00,900 --> 00:02:03,460
右邊這張表 解釋了 True Positive

39
00:02:03,460 --> 00:02:04,580
True Negative

40
00:02:04,580 --> 00:02:07,300
False Positive和 False Negative的定義

41
00:02:07,300 --> 00:02:11,540
好的 這張投影片我們來看看模型評估的指標

42
00:02:11,540 --> 00:02:18,860
首先 Precision 精準度 他衡量的是所有預測爲證的樣本中真正爲證的比例公式在上面

43
00:02:18,860 --> 00:02:24,020
接下來 Recall 照回率也叫做 True Positive Rate或者 Sensitivity

44
00:02:24,020 --> 00:02:29,460
他衡量的是所有實際爲證的樣本中被證確於測爲證的比例公式也在上面

45
00:02:29,460 --> 00:02:33,620
最後 FESCORE 是 Precision和 Recall的調和平均數

46
00:02:33,620 --> 00:02:37,860
他綜合考慮了 Precision和 Recall 公式也幫大家列出來了

47
00:02:37,860 --> 00:02:40,020
好的 我們來看兩個實際例子

48
00:02:40,020 --> 00:02:43,780
有兩個模型 分別給出了Score 也就是預測的信心程度

49
00:02:43,780 --> 00:02:47,020
我們看左邊這個例子 模型說信心程度是0.7

50
00:02:47,020 --> 00:02:50,580
那我們就看 實際是0跟1分別有多少比例證確

51
00:02:50,580 --> 00:02:52,860
實際是0的有6個被預測證確

52
00:02:52,860 --> 00:02:55,220
實際是1的只有1個被預測證確

53
00:02:55,220 --> 00:02:58,580
所以我們可以算出來 Precision是0.25

54
00:02:58,580 --> 00:03:02,340
同樣的方式我們看右邊的例子 模型信心程度是0.8

55
00:03:02,340 --> 00:03:06,300
結果計算出來 Precision 確變成0 也就是預測全錯了

