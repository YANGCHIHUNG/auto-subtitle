1
00:00:00,000 --> 00:00:04,400
好的,接下來這張投影片是我們研究的題目以及一些基本資訊

2
00:00:04,600 --> 00:00:09,920
我們的研究題目是基於綠色學習和判別特徵測試的輕量集心電圖心率不整辨識研究

3
00:00:10,040 --> 00:00:16,680
英文標題是ECG HOP,A lightweight ECG Arrhythmia classification based on green learning and discriminate feature test

4
00:00:16,960 --> 00:00:18,640
指導教授是陳煥教授

5
00:00:19,040 --> 00:00:21,400
而我是報告人,研究生陳又云

6
00:00:21,680 --> 00:00:25,960
這張投影片主要是讓大家知道我們的研究題目和團隊成員

7
00:00:26,600 --> 00:00:30,360
好的,各位聽衆,這張投影片是我們報告的目錄

8
00:00:30,560 --> 00:00:33,400
讓大家對整個研究的架構有個清晰的瞭解

9
00:00:33,720 --> 00:00:36,360
首先,我們會從研究動機與貢獻開始

10
00:00:36,560 --> 00:00:40,200
說明我們未識模要做這個研究以及它能帶來什麼樣的價值

11
00:00:40,560 --> 00:00:44,200
接着,彙集相關的背景知識和過去的研究成果

12
00:00:44,400 --> 00:00:46,280
讓大家瞭解我們研究的基礎

13
00:00:46,640 --> 00:00:49,800
再來,會詳細說明我們所使用的研究方法

14
00:00:50,160 --> 00:00:52,240
然後,我們會呈現實驗的結果

15
00:00:52,480 --> 00:00:53,520
並加以分析說明

16
00:00:53,920 --> 00:00:56,000
最後,我們會總結研究的發現

17
00:00:56,000 --> 00:00:58,280
並提出未來研究的方向和建議

18
00:00:58,680 --> 00:00:59,760
最後是參考資料

19
00:01:00,120 --> 00:01:02,040
列出我們研究過程中參考的文獻

20
00:01:02,440 --> 00:01:03,480
希望透過這個目錄

21
00:01:03,840 --> 00:01:06,040
大家可以更清楚的掌握我們報告的內容

22
00:01:06,800 --> 00:01:09,920
好的,針對這張投影片,我的講道如下

23
00:01:10,320 --> 00:01:14,440
各位,這張投影片主要跟大家說明我們研究的動機與貢獻

24
00:01:14,840 --> 00:01:18,520
首先,心律不整是各影響心血管健康的重要疾病

25
00:01:18,800 --> 00:01:21,360
嚴重的話甚至可能導致心臟驟停

26
00:01:21,840 --> 00:01:25,200
所以,快速準確的辨識心律不整非常重要

27
00:01:25,680 --> 00:01:27,960
但問題來了,現在流行的穿戴裝置

28
00:01:28,320 --> 00:01:29,880
運算能力其實很有限

29
00:01:30,400 --> 00:01:32,640
如果直接用深度學習,雖然準確

30
00:01:32,960 --> 00:01:35,440
但計算量太大,穿戴裝置根本跑不動

31
00:01:35,880 --> 00:01:38,040
再來,新電圖資料非常龐大

32
00:01:38,320 --> 00:01:40,720
光靠醫生人工判讀,非常耗時費力

33
00:01:41,240 --> 00:01:43,800
所以,如何從大量的ECG訊號中

34
00:01:44,080 --> 00:01:45,840
快速篩選出關鍵的診斷資訊

35
00:01:45,840 --> 00:01:47,480
就成了我們研究的核心議題

36
00:01:48,360 --> 00:01:51,160
好的,針對這張投影片,我來說明一下

37
00:01:51,400 --> 00:01:52,640
我們的研究動機與貢獻

38
00:01:53,120 --> 00:01:56,640
首先,我們觀察到ECG資料在訓練時期算量很大

39
00:01:57,120 --> 00:02:00,200
因此,我們結合了綠色學習和判別特徵測試

40
00:02:00,200 --> 00:02:02,360
也就是投影片上提到的ECG HOP

41
00:02:02,640 --> 00:02:04,320
目標是在降低訓練時間的同時

42
00:02:04,560 --> 00:02:06,280
仍然能保持優異的F1分數

43
00:02:06,760 --> 00:02:09,440
第二,我們將意味的原始ECG訊號

44
00:02:09,440 --> 00:02:12,040
轉換成32x32的幾座標識平圖

45
00:02:12,320 --> 00:02:14,000
以便後續的分析和模型訓練

46
00:02:14,480 --> 00:02:16,440
第三,針對資料不平衡的問題

47
00:02:16,440 --> 00:02:18,320
我們採用了SmokeTomec方法

48
00:02:18,600 --> 00:02:20,320
並結合XGBoost模型

49
00:02:20,600 --> 00:02:22,760
希望能有效改善資料不平衡的狀況

50
00:02:22,760 --> 00:02:24,080
進而增強分類效能

51
00:02:24,520 --> 00:02:27,000
最後,我們的成果展現在並證變時尚

52
00:02:27,000 --> 00:02:29,280
加全F1分數達到了0.78

53
00:02:29,600 --> 00:02:31,280
而且訓練時間只需要5分鐘

54
00:02:31,680 --> 00:02:32,600
這個結果顯示

55
00:02:32,600 --> 00:02:34,960
我們的方法在效率和準確度上

56
00:02:34,960 --> 00:02:35,920
都有不錯的表現

57
00:02:36,680 --> 00:02:37,800
好的,大家好

58
00:02:38,320 --> 00:02:39,200
這張投影片

59
00:02:39,200 --> 00:02:41,480
主要跟大家介紹一下新電圖的背景知識

60
00:02:41,880 --> 00:02:44,600
新電圖是現代醫學裏面很重要的一種工具

61
00:02:44,880 --> 00:02:46,720
它主要用來檢測各種心臟疾病

62
00:02:47,160 --> 00:02:50,000
它的原理其實就是記錄我們每次心跳時

63
00:02:50,160 --> 00:02:51,560
心臟產生的電位變化

64
00:02:52,000 --> 00:02:53,200
大家看到的新電圖

65
00:02:53,480 --> 00:02:55,040
通常都會以波形的方式呈現

66
00:02:55,480 --> 00:02:56,160
簡單來說

67
00:02:56,520 --> 00:02:59,120
新電圖就是醫生們用來了解我們心臟健康

68
00:02:59,120 --> 00:03:00,560
狀況的一個重要指標

69
00:03:01,400 --> 00:03:01,720
好的

70
00:03:02,160 --> 00:03:04,440
接下來我們看到背景知識與相關研究這部分

71
00:03:04,920 --> 00:03:07,000
這頁投影片主要介紹了新電圖

72
00:03:07,240 --> 00:03:08,440
也就是ECG

73
00:03:08,880 --> 00:03:10,760
新電圖在我們這次的研究中

74
00:03:10,760 --> 00:03:11,840
扮演很重要的角色

75
00:03:12,280 --> 00:03:12,720
首先

76
00:03:13,000 --> 00:03:14,680
我們先看到單導成心電圖

77
00:03:14,920 --> 00:03:16,520
它主要用在基礎的心率監測

78
00:03:16,520 --> 00:03:18,800
可以快速瞭解心跳是否正常

79
00:03:19,240 --> 00:03:19,680
另外

80
00:03:20,040 --> 00:03:21,400
如果需要更全面的檢查

81
00:03:21,640 --> 00:03:23,160
我們會使用多導成心電圖

82
00:03:23,560 --> 00:03:25,040
它會用到10個電機貼片

83
00:03:25,320 --> 00:03:27,000
可以更詳細的分析心臟功能

84
00:03:27,800 --> 00:03:28,160
好的

85
00:03:28,600 --> 00:03:30,000
我們來看一下第6張投影片

86
00:03:30,440 --> 00:03:32,320
這張主要是在介紹綠色學習

87
00:03:32,320 --> 00:03:33,720
也就是Green Learning

88
00:03:34,120 --> 00:03:36,360
它是一種新型的輕量級分類模型

89
00:03:36,800 --> 00:03:38,440
核心概念是透過主層學習

90
00:03:38,440 --> 00:03:39,680
建立一個多層結構

91
00:03:39,960 --> 00:03:41,560
而且是無監督的特徵學習

92
00:03:41,960 --> 00:03:43,200
這個多層結構的每一層

93
00:03:43,200 --> 00:03:44,680
都包含了三個重要的單元

94
00:03:44,920 --> 00:03:45,920
Pixel Hub單元

95
00:03:45,920 --> 00:03:46,800
聚合模組

96
00:03:46,800 --> 00:03:47,880
以及Lag單元

97
00:03:48,240 --> 00:03:50,440
後續的投影片會更詳細的說明

98
00:03:50,440 --> 00:03:51,520
這三個單元的功能

99
00:03:52,280 --> 00:03:52,680
好的

100
00:03:52,960 --> 00:03:54,760
接下來我們看到這張投影片

101
00:03:54,760 --> 00:03:57,240
主要講的是我們綠色學習方法中

102
00:03:57,480 --> 00:03:59,480
提取特徵圖像Pixel Hub單元的

103
00:03:59,480 --> 00:04:00,160
背景知識

104
00:04:00,560 --> 00:04:02,480
Pixel Hub的核心包含兩個步驟

105
00:04:02,480 --> 00:04:04,360
鄰居建構和Sawb變換

106
00:04:04,760 --> 00:04:05,280
首先

107
00:04:05,520 --> 00:04:07,440
鄰居建構就是針對每個像素

108
00:04:07,600 --> 00:04:08,840
取它周圍的8個鄰居點

109
00:04:09,000 --> 00:04:10,200
這樣我們就能得到

110
00:04:11,480 --> 00:04:12,800
9K的資料結構

111
00:04:12,800 --> 00:04:13,840
準備進入下一步

112
00:04:14,200 --> 00:04:16,160
接下來就是這個Sawb變換了

113
00:04:16,600 --> 00:04:17,360
Sawb變換

114
00:04:17,680 --> 00:04:20,160
是一個基於主成分分析PCA的

115
00:04:20,160 --> 00:04:20,920
線性變換

116
00:04:21,200 --> 00:04:23,760
它能將鄰居聯合特徵進行壓縮和

117
00:04:23,760 --> 00:04:24,240
降維

118
00:04:24,400 --> 00:04:25,120
簡單來說

119
00:04:25,120 --> 00:04:27,840
就是把N星號N9K的資料

120
00:04:28,000 --> 00:04:30,080
通過PCA來提取最重要的資訊

121
00:04:30,080 --> 00:04:31,000
去除榮譽

122
00:04:31,120 --> 00:04:32,680
爲後續的處理打下基礎

123
00:04:33,360 --> 00:04:33,840
好的

124
00:04:34,240 --> 00:04:35,280
針對這張投影片

125
00:04:35,520 --> 00:04:36,560
我來簡單說明一下

126
00:04:36,880 --> 00:04:39,320
這張投影片主要講的是背景知識

127
00:04:39,320 --> 00:04:40,400
以及相關研究

128
00:04:40,400 --> 00:04:41,600
聚焦在兩個部分

129
00:04:41,920 --> 00:04:44,040
首先是綠色學習Green Learning

130
00:04:44,160 --> 00:04:46,000
這個概念是我們研究的基礎之一

131
00:04:46,160 --> 00:04:48,160
後續會進一步說明它跟我們方法的

132
00:04:48,160 --> 00:04:48,640
關聯

133
00:04:48,920 --> 00:04:49,520
另外

134
00:04:49,680 --> 00:04:51,720
我們也運用了壓縮特徵聚合模組

135
00:04:51,800 --> 00:04:53,440
也就是針對區域內的特徵

136
00:04:53,480 --> 00:04:54,640
計算最大值

137
00:04:54,640 --> 00:04:55,360
最小值

138
00:04:55,360 --> 00:04:56,240
或平均值

139
00:04:56,240 --> 00:04:57,760
來達到壓縮特徵的目的

140
00:04:57,960 --> 00:04:59,600
最後Lag單元

141
00:04:59,600 --> 00:05:01,400
是我們用來將高爲度向量

142
00:05:01,400 --> 00:05:03,480
映射到低爲度向量的關鍵技術

143
00:05:03,600 --> 00:05:05,480
這可以有效降低運算複雜度

144
00:05:05,680 --> 00:05:07,760
這三個點是我們背景研究中

145
00:05:07,760 --> 00:05:08,840
比較重要的部分

146
00:05:09,480 --> 00:05:10,040
好的

147
00:05:10,360 --> 00:05:11,520
針對這張投影片

148
00:05:11,760 --> 00:05:12,640
我們可以這樣講

149
00:05:12,960 --> 00:05:15,040
接下來我們談談研究方法

150
00:05:15,360 --> 00:05:16,600
這份研究主要使用

151
00:05:16,600 --> 00:05:19,160
PhysioNet2017這個公開的資料集

152
00:05:19,480 --> 00:05:21,120
這個資料集裏的新電圖訊號

153
00:05:21,120 --> 00:05:22,240
我們主要分爲四類

154
00:05:22,280 --> 00:05:23,640
第一類是心房顫動

155
00:05:23,640 --> 00:05:24,880
Atreo Fibrillation

156
00:05:24,880 --> 00:05:25,800
也就是AF

157
00:05:25,840 --> 00:05:28,080
特徵是心跳快速且不規律

158
00:05:28,320 --> 00:05:29,760
第二類是normal

159
00:05:29,760 --> 00:05:31,920
代表規律的心跳和穩定的節奏

160
00:05:32,200 --> 00:05:33,520
第三類是other

161
00:05:33,680 --> 00:05:35,880
涵蓋了其他不同的異常波形變化

162
00:05:36,160 --> 00:05:38,080
最後一類是Noisy

163
00:05:38,200 --> 00:05:39,600
代表訊號受到干擾

164
00:05:39,600 --> 00:05:41,680
或者是飛聲裏訊號產生的雜訊

165
00:05:42,280 --> 00:05:42,840
好的

166
00:05:42,920 --> 00:05:43,600
大家好

167
00:05:43,960 --> 00:05:44,880
這張投影片

168
00:05:44,880 --> 00:05:46,360
主要介紹我們的研究方法

169
00:05:46,440 --> 00:05:47,800
特別是資料集的部分

170
00:05:48,040 --> 00:05:50,840
首先我們使用的是PhysioNet2017

171
00:05:50,880 --> 00:05:51,720
這個資料集

172
00:05:51,960 --> 00:05:53,360
這是原始資料集

173
00:05:53,440 --> 00:05:55,440
我們並沒有做額外的修改

174
00:05:55,680 --> 00:05:58,120
接着爲了訓練和驗證模型

175
00:05:58,160 --> 00:05:59,560
我們將這個原始資料集

176
00:05:59,560 --> 00:06:00,880
按照8比2的比例

177
00:06:00,920 --> 00:06:02,880
切分成訓練集和驗證集

178
00:06:03,080 --> 00:06:05,400
80%的資料用於訓練模型

179
00:06:05,440 --> 00:06:08,200
剩下的20%用於評估模型的效能

180
00:06:08,800 --> 00:06:09,400
好的

181
00:06:09,520 --> 00:06:11,720
這張投影片主要講研究方法

182
00:06:11,760 --> 00:06:12,760
更具體來說

183
00:06:12,800 --> 00:06:14,680
是關於我們研究的系統概觀

184
00:06:14,880 --> 00:06:15,600
接下來

185
00:06:15,600 --> 00:06:16,800
我們會在細節哨系統的

186
00:06:16,800 --> 00:06:18,360
整體架構和運作方式

187
00:06:18,400 --> 00:06:20,200
讓大家對我們的研究方向

188
00:06:20,200 --> 00:06:21,480
有個更全面的瞭解

189
00:06:21,680 --> 00:06:23,160
第12張投影片之後

190
00:06:23,200 --> 00:06:24,960
會更深入的去講解細節

191
00:06:25,560 --> 00:06:26,200
好的

192
00:06:26,360 --> 00:06:28,280
接下來我們看到第12張投影片

193
00:06:28,400 --> 00:06:30,160
這張主要是關於研究方法

194
00:06:30,360 --> 00:06:32,560
重點就在於資料預處理流程

195
00:06:32,800 --> 00:06:34,120
這部分是整個研究中

196
00:06:34,120 --> 00:06:35,280
非常重要的一環

197
00:06:35,320 --> 00:06:36,120
它直接影響到

198
00:06:36,120 --> 00:06:37,600
後續分析結果的準確性

199
00:06:37,640 --> 00:06:39,080
所以在這個階段

200
00:06:39,240 --> 00:06:40,440
我們會花比較多的時間

201
00:06:40,440 --> 00:06:41,440
和精力去處理

202
00:06:42,040 --> 00:06:42,640
好的

203
00:06:42,800 --> 00:06:43,360
各位

204
00:06:43,560 --> 00:06:45,400
接下來我們看到研究方法的部分

205
00:06:45,560 --> 00:06:46,920
這張投影片主要聚焦

206
00:06:46,920 --> 00:06:48,280
在資料預處理的流程

207
00:06:48,520 --> 00:06:49,320
也就是說

208
00:06:49,360 --> 00:06:50,880
在我們開始分析資料之前

209
00:06:50,920 --> 00:06:52,760
需要先進行哪些步驟來清理

210
00:06:52,800 --> 00:06:54,200
轉換和準備資料

211
00:06:54,240 --> 00:06:55,400
確保資料的品質

212
00:06:55,440 --> 00:06:56,760
這樣才能讓後續的分析

213
00:06:56,800 --> 00:06:57,960
更加準確可靠

214
00:06:58,560 --> 00:06:59,120
好的

215
00:06:59,200 --> 00:06:59,800
各位

216
00:07:00,000 --> 00:07:02,160
現在我們來到研究方法的章節

217
00:07:02,320 --> 00:07:03,720
這張投影片主要聚焦

218
00:07:03,720 --> 00:07:04,920
在訓練流程的部分

219
00:07:05,200 --> 00:07:06,960
接下來我們會詳細說明

220
00:07:07,000 --> 00:07:09,200
我們具體的研究是如何進行的

221
00:07:09,280 --> 00:07:10,880
以及資料是如何被運用到

222
00:07:10,880 --> 00:07:12,040
我們的模型訓練中的

223
00:07:12,520 --> 00:07:13,120
好的

224
00:07:13,240 --> 00:07:13,880
各位

225
00:07:14,040 --> 00:07:16,400
我們現在看到的是第15張投影片

226
00:07:16,520 --> 00:07:18,480
主要講的是我們的研究方法

227
00:07:18,680 --> 00:07:19,960
這張投影片的重點

228
00:07:19,960 --> 00:07:21,880
是介紹我們使用的核心模型

229
00:07:21,880 --> 00:07:22,760
Pixel Hub

230
00:07:22,960 --> 00:07:25,080
稍後我們會詳細介紹Pixel Hub

231
00:07:25,080 --> 00:07:26,320
模型的具體細節

232
00:07:26,520 --> 00:07:28,640
接下來會進入第16張投影片

233
00:07:29,240 --> 00:07:29,840
好的

234
00:07:29,960 --> 00:07:30,760
各位觀衆

235
00:07:30,960 --> 00:07:32,760
接下來我們看到研究方法這部分

236
00:07:32,960 --> 00:07:34,880
這張投影片主要介紹我們用到的

237
00:07:34,880 --> 00:07:36,040
資料擴增技術

238
00:07:36,080 --> 00:07:37,680
也就是Small Toe Mac

239
00:07:37,880 --> 00:07:40,240
Small Toe Mac結合了Small過彩樣

240
00:07:40,280 --> 00:07:42,520
和Toe Mac Wins清理這兩種方法

241
00:07:42,720 --> 00:07:44,680
這模作的目的是爲了改善資料

242
00:07:44,680 --> 00:07:45,600
不平衡的問題

243
00:07:45,720 --> 00:07:47,800
讓我們的模型訓練可以更有效率

244
00:07:48,360 --> 00:07:49,000
好的

245
00:07:49,160 --> 00:07:50,440
第17張投影片

246
00:07:50,600 --> 00:07:52,280
我們聚焦在研究方法的部分

247
00:07:52,480 --> 00:07:55,080
這張投影片主要講的就是判別特徵

248
00:07:55,080 --> 00:07:55,640
測試

249
00:07:55,640 --> 00:07:57,080
也就是DFT

250
00:07:57,240 --> 00:07:59,240
這是我們研究中很重要的一個環節

251
00:07:59,320 --> 00:08:00,640
用來辨識和測試

252
00:08:00,640 --> 00:08:02,240
我們所關注的關鍵特徵

253
00:08:02,800 --> 00:08:03,400
好的

254
00:08:03,520 --> 00:08:05,280
現在我們看到第18張投影片

255
00:08:05,360 --> 00:08:07,160
主要呈現的是實驗結果

256
00:08:07,400 --> 00:08:09,040
這些的重點在於定義

257
00:08:09,080 --> 00:08:10,840
我們用來評估模型效能的指標

258
00:08:10,880 --> 00:08:12,280
也就是precision

259
00:08:12,320 --> 00:08:12,920
精確度

260
00:08:12,920 --> 00:08:13,520
recall

261
00:08:13,560 --> 00:08:14,240
照回率

262
00:08:14,280 --> 00:08:15,600
以及Fescore

263
00:08:15,880 --> 00:08:16,600
首先

264
00:08:16,640 --> 00:08:19,320
precision代表的是我們預測爲正立的樣本中

265
00:08:19,360 --> 00:08:20,560
真正爲正立的比例

266
00:08:20,560 --> 00:08:21,840
公式是TP

267
00:08:21,880 --> 00:08:23,120
TP加FP

268
00:08:23,320 --> 00:08:24,320
簡單來說

269
00:08:24,440 --> 00:08:26,480
它衡量的是預測的準確性

270
00:08:26,680 --> 00:08:28,120
接下來是recall

271
00:08:28,240 --> 00:08:31,040
它代表的是所有真正爲正立的樣本中

272
00:08:31,080 --> 00:08:32,680
被我們成功預測出來的比例

273
00:08:32,680 --> 00:08:33,960
公式是TP

274
00:08:34,000 --> 00:08:35,280
TP加FM

275
00:08:35,520 --> 00:08:37,840
recall衡量的是我們模型的覆蓋率

276
00:08:37,880 --> 00:08:39,240
也就是能不能進

277
00:08:39,240 --> 00:08:40,560
可能找到所有的正立

278
00:08:40,760 --> 00:08:41,400
最後

279
00:08:41,440 --> 00:08:45,040
Fescore是一個綜合precision和recall的指標

280
00:08:45,080 --> 00:08:47,600
它是precision和recall的調和平均數

281
00:08:47,600 --> 00:08:49,000
公式在投影片上也有

282
00:08:49,000 --> 00:08:50,880
可以更全面的評估模型的效能

283
00:08:51,200 --> 00:08:53,560
我們會根據這些指標來判斷模型的表現

284
00:08:54,240 --> 00:08:54,840
好的

285
00:08:54,960 --> 00:08:57,280
這張投影片展示了我們實驗的結果

286
00:08:57,400 --> 00:08:58,240
具體來說

287
00:08:58,280 --> 00:09:00,560
是我們方法所使用的模型參數量

288
00:09:00,800 --> 00:09:01,800
重點就是這裏

289
00:09:01,920 --> 00:09:02,840
大家可以看到

290
00:09:02,840 --> 00:09:04,440
我們模型的參數量是多少

291
00:09:05,040 --> 00:09:05,640
好的

292
00:09:05,720 --> 00:09:06,360
各位

293
00:09:06,520 --> 00:09:09,200
這張投影片展示我們方法實驗的結果

294
00:09:09,440 --> 00:09:10,320
具體來說

295
00:09:10,360 --> 00:09:12,920
我們呈現了各個類別的ROCK曲線面積

296
00:09:12,960 --> 00:09:13,680
AUC

297
00:09:13,880 --> 00:09:15,840
AUC這個指標可以幫我們瞭解

298
00:09:15,840 --> 00:09:17,840
模型在不同類別上的分類能力

299
00:09:18,040 --> 00:09:19,040
AUC越高

300
00:09:19,040 --> 00:09:21,040
代表模型在這個類別的表現越好

301
00:09:21,240 --> 00:09:22,600
接下來幾張投影片

302
00:09:22,720 --> 00:09:24,480
我們會更詳細的分析這些結果

303
00:09:24,520 --> 00:09:26,160
並和其他方法進行比較

304
00:09:26,720 --> 00:09:27,320
好的

305
00:09:27,480 --> 00:09:29,040
接下來我們看到實驗結果

306
00:09:29,200 --> 00:09:31,040
這張投影片主要展示的是

307
00:09:31,080 --> 00:09:32,840
我們方法產生的混小矩陣

308
00:09:33,040 --> 00:09:34,120
從這個矩陣中

309
00:09:34,160 --> 00:09:35,040
大家可以看到

310
00:09:35,080 --> 00:09:37,200
我們模型在各個類別上的表現情況

311
00:09:37,240 --> 00:09:38,120
也就是說

312
00:09:38,160 --> 00:09:39,400
他成功預測了哪些

313
00:09:39,400 --> 00:09:40,640
又在哪裏容易出錯

314
00:09:40,800 --> 00:09:43,040
這對於我們進一步分析和優化模型

315
00:09:43,040 --> 00:09:43,920
非常重要

316
00:09:44,480 --> 00:09:45,080
好的

317
00:09:45,200 --> 00:09:47,200
現在我們看到第22張投影片

318
00:09:47,240 --> 00:09:49,560
這張投影片的標題是實驗結果

319
00:09:49,760 --> 00:09:50,560
接下來

320
00:09:50,640 --> 00:09:52,720
我們看到的是本文方法實驗結果

321
00:09:52,720 --> 00:09:54,280
隨機實筆實驗結果

322
00:09:54,520 --> 00:09:56,520
這部分呈現的是我們使用的方法

323
00:09:56,520 --> 00:09:57,520
進行實驗後

324
00:09:57,560 --> 00:09:59,520
隨機選取的實筆結果數據

325
00:09:59,680 --> 00:10:00,760
後面的投影片

326
00:10:00,760 --> 00:10:02,680
應該會更詳細的呈現這些數據

327
00:10:02,720 --> 00:10:04,160
以及他們所代表的意義

328
00:10:04,720 --> 00:10:05,320
好的

329
00:10:05,520 --> 00:10:06,800
接下來我們看到實驗結果

330
00:10:06,800 --> 00:10:07,640
這張投影片

331
00:10:07,880 --> 00:10:09,880
這也主要呈現的是不同模型

332
00:10:09,880 --> 00:10:12,400
在參數大小和訓練時間上的比較

333
00:10:12,600 --> 00:10:13,440
可以看到

334
00:10:13,600 --> 00:10:14,880
我們針對不同模型

335
00:10:14,920 --> 00:10:16,120
記錄了他們的參數量

336
00:10:16,120 --> 00:10:17,760
以及訓練所需的具體時間

337
00:10:17,800 --> 00:10:19,280
藉此來評估模型的效率

338
00:10:19,480 --> 00:10:21,720
希望這個比較能幫助大家理解

339
00:10:21,720 --> 00:10:23,480
不同模型之間的效能差異

340
00:10:24,080 --> 00:10:25,280
好的各位

341
00:10:25,480 --> 00:10:26,280
接下來

342
00:10:26,320 --> 00:10:28,120
我們看到實驗結果這張投影片

343
00:10:28,360 --> 00:10:30,360
這也主要呈現的是不同模型

344
00:10:30,360 --> 00:10:32,840
在參數大小以及訓練時間上的比較

345
00:10:33,040 --> 00:10:34,080
圖表中的數據

346
00:10:34,120 --> 00:10:35,240
大家可以仔細看一下

347
00:10:35,440 --> 00:10:37,600
主要是想讓大家瞭解不同模型

348
00:10:37,600 --> 00:10:39,280
規模和訓練時間投入

349
00:10:39,320 --> 00:10:40,840
對應的效能表現差異

350
00:10:41,080 --> 00:10:43,320
這樣有助於我們後續在模型選擇

351
00:10:43,320 --> 00:10:45,560
和訓練策略上做出更明智的決策

352
00:10:46,160 --> 00:10:46,720
好的

353
00:10:46,880 --> 00:10:47,720
這張投影片

354
00:10:47,720 --> 00:10:48,960
我們來看實驗結果

355
00:10:49,000 --> 00:10:50,880
重點是Pixel Hub模型

356
00:10:50,920 --> 00:10:52,440
特別是關於Saw不變換的

357
00:10:52,440 --> 00:10:54,240
AC濾波器參數分析

358
00:10:54,480 --> 00:10:56,080
我們主要會關注這些參數

359
00:10:56,080 --> 00:10:57,720
是如何影響模型表現的

360
00:10:57,840 --> 00:10:59,000
以及怎樣調整他們

361
00:10:59,000 --> 00:11:00,320
才能獲得更好的效果

362
00:11:00,960 --> 00:11:01,480
好的

363
00:11:01,680 --> 00:11:02,320
大家好

364
00:11:02,560 --> 00:11:03,480
這張投影片

365
00:11:03,480 --> 00:11:05,080
主要呈現的是實驗結果

366
00:11:05,200 --> 00:11:07,520
特別是重在資料擴增的分析上

367
00:11:07,720 --> 00:11:09,560
我們會仔細探討資料擴增

368
00:11:09,560 --> 00:11:11,280
對於模型表現的影響

369
00:11:11,320 --> 00:11:12,920
並且在接下來的投影片中

370
00:11:12,920 --> 00:11:15,400
深入分析具體的實驗數據和結果

371
00:11:15,920 --> 00:11:16,520
好的

372
00:11:16,640 --> 00:11:18,680
現在我們看到第27張投影片

373
00:11:18,720 --> 00:11:20,920
這一張呈現的是我們的實驗結果

374
00:11:21,120 --> 00:11:23,080
主要焦點在於DFT

375
00:11:23,120 --> 00:11:24,400
離散負力葉轉換

376
00:11:24,440 --> 00:11:25,840
特徵選擇的效能比較

377
00:11:26,040 --> 00:11:27,120
這張投影片的核心

378
00:11:27,120 --> 00:11:28,720
就是評估DFT特徵

379
00:11:28,720 --> 00:11:30,200
選擇在我們研究中的表現

380
00:11:30,440 --> 00:11:32,480
稍後會更詳細地說明這些結果

381
00:11:33,120 --> 00:11:33,680
好的

382
00:11:33,800 --> 00:11:34,560
各位觀衆

383
00:11:34,800 --> 00:11:37,040
現在我們看到的是實驗結果這部分

384
00:11:37,320 --> 00:11:39,280
這張投影片主要呈現的是

385
00:11:39,400 --> 00:11:41,160
我們不同分類器的效能比較

386
00:11:41,440 --> 00:11:42,400
所以接下來

387
00:11:42,520 --> 00:11:44,640
我們會在細節是各個分類器

388
00:11:44,640 --> 00:11:45,800
在實驗中的表現

389
00:11:45,840 --> 00:11:47,040
以及它們之間的差異

390
00:11:47,600 --> 00:11:48,160
好的

391
00:11:48,400 --> 00:11:50,360
接下來我們看到結論與未來展望

392
00:11:50,600 --> 00:11:52,680
我們提出的ECG HOP模型

393
00:11:52,720 --> 00:11:54,240
在效能和計算時間上

394
00:11:54,240 --> 00:11:55,560
取得了一個不錯的平衡

395
00:11:55,800 --> 00:11:56,760
大家可以看到

396
00:11:56,800 --> 00:11:57,680
在Normal

397
00:11:57,720 --> 00:11:59,840
AF和Ader三種類型的心率不整

398
00:11:59,840 --> 00:12:00,440
判斷上

399
00:12:00,480 --> 00:12:01,840
分別達到了0.85

400
00:12:01,880 --> 00:12:02,600
0.80

401
00:12:02,600 --> 00:12:04,040
和0.63的準確度

402
00:12:04,240 --> 00:12:05,120
更重要的是

403
00:12:05,200 --> 00:12:07,280
這個模型只需要CPU訓練

404
00:12:07,320 --> 00:12:09,000
而且僅僅5分鐘就能完成

405
00:12:09,040 --> 00:12:11,240
參數數量也只有132.2K

406
00:12:11,280 --> 00:12:13,480
非常適合在資源受限的環境中使用

407
00:12:13,720 --> 00:12:14,320
因此

408
00:12:14,480 --> 00:12:16,400
我們認爲未來可以將這個模型

409
00:12:16,400 --> 00:12:17,880
結合邊緣運算技術

410
00:12:17,920 --> 00:12:20,240
及時應用在像是穿戴式裝置

411
00:12:20,280 --> 00:12:22,280
救護車或行動醫療裝置上

412
00:12:22,480 --> 00:12:23,120
另外

413
00:12:23,280 --> 00:12:25,000
我們也希望可以進一步設計

414
00:12:25,000 --> 00:12:26,840
使用餘多導成芯電圖的模型

415
00:12:27,000 --> 00:12:29,120
這樣就能夠提供更全面的心率資訊

416
00:12:29,160 --> 00:12:31,320
幫助我們判斷更多類型的心率不整

